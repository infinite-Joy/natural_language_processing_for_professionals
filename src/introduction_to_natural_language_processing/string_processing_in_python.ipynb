{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "string_processing_in_python",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## The `str` type."
      ],
      "metadata": {
        "id": "twjhen423-ci"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7tbEADIsKs5",
        "outputId": "04ebf95e-cbc9-44ec-d077-14ba39f73fd5"
      },
      "source": [
        "text = \"quick brown fox jumps over the lazy dog.\"\n",
        "print(type(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with Unicode"
      ],
      "metadata": {
        "id": "fotNJAUn4G-t"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgZnAzSYsQmV",
        "outputId": "04f91c88-2eae-438a-f642-b5879cda1cb1"
      },
      "source": [
        "text = \"El Ni√±o\".encode(\"utf-8\")\n",
        "print('original text: ', text)\n",
        "print('text after decoding: ', text.decode(\"utf-8\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original text:  b'El Ni\\xc3\\xb1o'\n",
            "text after decoding:  El Ni√±o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Size of different strings"
      ],
      "metadata": {
        "id": "latP8BSP4M7s"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzbBYcY-sSZO",
        "outputId": "ce1c4f17-2c2a-411b-9102-f59563ba0ad3"
      },
      "source": [
        "import sys\n",
        "string = 'hello'\n",
        "print(sys.getsizeof(string))\n",
        "\n",
        "# one byte encoding\n",
        "print(sys.getsizeof(string+'!')-sys.getsizeof(string))\n",
        "\n",
        "# 2-byte encoding\n",
        "string2  = '‡¶Ö'\n",
        "print(sys.getsizeof(string2+'‡¶Ö')-sys.getsizeof(string2))\n",
        "print(sys.getsizeof(string2))\n",
        "\n",
        "# 4-byte encoding\n",
        "string3 = 'üêç'\n",
        "print(sys.getsizeof(string3+'üíª')-sys.getsizeof(string3))\n",
        "print(sys.getsizeof(string3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n",
            "1\n",
            "2\n",
            "76\n",
            "4\n",
            "80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common Python string methods\n",
        "\n",
        "### Character lengths and word lengths"
      ],
      "metadata": {
        "id": "63_tFyx14T8E"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNCEOA3HsUIh",
        "outputId": "4ca135b5-34e2-4fb6-bd32-163377a0dfc0"
      },
      "source": [
        "string = 'natural language processing for professionals'\n",
        "print('character length of the sentence:', len(string))\n",
        "\n",
        "words = string.split()\n",
        "print('word length of the sentence:', len(words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "character length of the sentence: 45\n",
            "word length of the sentence: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Character frequency"
      ],
      "metadata": {
        "id": "XdC3i4Fi4bGL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzM2TV8ssXGb",
        "outputId": "d300fc5c-e3f8-431e-88d6-36a6b24ea32c"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "print(Counter('natural language processing for professionals'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'a': 5, 's': 5, 'n': 4, 'r': 4, ' ': 4, 'o': 4, 'l': 3, 'g': 3, 'e': 3, 'u': 2, 'p': 2, 'i': 2, 'f': 2, 't': 1, 'c': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pattern Search"
      ],
      "metadata": {
        "id": "q_2c54yB4eDW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLKiMjEtsZYu",
        "outputId": "23603deb-a9ab-42bb-beed-5470e638a579"
      },
      "source": [
        "spam_string = \"click on http://spam.com\"\n",
        "\n",
        "print('http' in spam_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BASnOWYzsa2V",
        "outputId": "837b1e9c-d474-48b2-a753-39ab5ab18fe6"
      },
      "source": [
        "import re\n",
        "\n",
        "def url_present(text):\n",
        "    pattern = 'http.*\\.com'\n",
        "    if re.search(pattern, spam_string):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "spam_string = \"click on http://spam.com\"\n",
        "print(url_present(spam_string))\n",
        "\n",
        "spam_string = \"update on ticket\"\n",
        "print(url_present(spam_string))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Strip whitespace"
      ],
      "metadata": {
        "id": "mtMbPC414kqd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1x4AxA_sfWV",
        "outputId": "cf7ac2e0-879b-4533-ef10-9a4d398b4cae"
      },
      "source": [
        "string_with_whitespace = \"    I am without whitespace. \\n\"\n",
        "string_without_whitespace = \"I am without whitespace.\"\n",
        "print('Equality of the two strings: ',\n",
        "  string_without_whitespace==string_with_whitespace)\n",
        "print('Equality of the strings after performing strip on string_without_whitespace: ',\n",
        "  string_with_whitespace.strip()==string_without_whitespace)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equality of the two strings:  False\n",
            "Equality of the strings after performing strip on string_without_whitespace:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting Strings"
      ],
      "metadata": {
        "id": "dYCKA_-24oeS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0800gS5OsijQ",
        "outputId": "5a7303d4-6b8d-4ba9-cffa-5acb6065cf1f"
      },
      "source": [
        "document = \"learning natural language processing\"\n",
        "print(document.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['learning', 'natural', 'language', 'processing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Joining list elements in a contiguous string"
      ],
      "metadata": {
        "id": "QT_W4Au44szv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUwylV7iske_",
        "outputId": "c71f920a-5391-4fd3-ae7c-0093c3c2b3d3"
      },
      "source": [
        "tokens = ['learning', 'natural', 'language', 'processing']\n",
        "print(\" \".join(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning natural language processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case of the string"
      ],
      "metadata": {
        "id": "5u99IXMC5GcU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxwm3ZYzsl24",
        "outputId": "8d050135-80e2-4fdb-8e11-2b8b16b69ad5"
      },
      "source": [
        "string = \"EDUCATIVE\"\n",
        "print('unique object identification of `string`', id(string))\n",
        "\n",
        "lower_case = string.lower()\n",
        "print('sentence in lower case: ', lower_case)\n",
        "print('unique object identification of `lower_case`', id(lower_case))\n",
        "\n",
        "upper_case = lower_case.upper()\n",
        "print('sentence in upper case: ', upper_case)\n",
        "print('unique object identification of `upper_case`', id(upper_case))\n",
        "\n",
        "print('is a match with the original text: ', upper_case == string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique object identification of `string` 140295863579824\n",
            "sentence in lower case:  educative\n",
            "unique object identification of `lower_case` 140295854557232\n",
            "sentence in upper case:  EDUCATIVE\n",
            "unique object identification of `upper_case` 140295854558704\n",
            "is a match with the original text:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas"
      ],
      "metadata": {
        "id": "DrwnpBe05Nlg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU6F60pasnWC",
        "outputId": "74a7d886-1444-40fa-b40e-f1908d627196"
      },
      "source": [
        "import pandas as pd\n",
        "s1 = pd.Series(\n",
        "    ['string processing using vanila python',\n",
        "     'string processing in pandas']\n",
        ")\n",
        "print(s1)\n",
        "print()\n",
        "print('converting all the strings to uppercase')\n",
        "print(s1.str.upper())\n",
        "print()\n",
        "print('converting all the strings to lowercase')\n",
        "print(s1.str.lower())\n",
        "print()\n",
        "print('split all the sentences to words')\n",
        "print(s1.str.strip().str.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    string processing using vanila python\n",
            "1              string processing in pandas\n",
            "dtype: object\n",
            "\n",
            "converting all the strings to uppercase\n",
            "0    STRING PROCESSING USING VANILA PYTHON\n",
            "1              STRING PROCESSING IN PANDAS\n",
            "dtype: object\n",
            "\n",
            "converting all the strings to lowercase\n",
            "0    string processing using vanila python\n",
            "1              string processing in pandas\n",
            "dtype: object\n",
            "\n",
            "split all the sentences to words\n",
            "0    [string, processing, using, vanila, python]\n",
            "1               [string, processing, in, pandas]\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Amazon reviews dataset"
      ],
      "metadata": {
        "id": "9c7q1zeY5RUy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_si4H-ltMry",
        "outputId": "0d5287d9-9a5e-42d4-a8bd-6949e4408e77"
      },
      "source": [
        "import urllib.request as req\n",
        "from urllib.parse import urlparse\n",
        "import os\n",
        "import progressbar\n",
        "import zipfile\n",
        "import gzip\n",
        "import shutil\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "\n",
        "pbar = None\n",
        "\n",
        "\n",
        "def show_progress(block_num, block_size, total_size):\n",
        "    global pbar\n",
        "    if pbar is None:\n",
        "        pbar = progressbar.ProgressBar(maxval=total_size)\n",
        "        pbar.start()\n",
        "\n",
        "    downloaded = block_num * block_size\n",
        "    if downloaded < total_size:\n",
        "        pbar.update(downloaded)\n",
        "    else:\n",
        "        pbar.finish()\n",
        "        pbar = None\n",
        "\n",
        "def wget(url):\n",
        "    a = urlparse(url)\n",
        "    filename = os.path.basename(a.path)\n",
        "    if not os.path.isfile(filename):\n",
        "        req.urlretrieve(url, filename, show_progress)\n",
        "        print(f'downloaded to {filename}')\n",
        "    else:\n",
        "        print(f'file {filename} has already been downloaded')\n",
        "    return filename\n",
        "\n",
        "def unzip(filename, directory_to_extract_to=os.getcwd()):\n",
        "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(directory_to_extract_to)\n",
        "        print(f'extraction done {zip_ref.namelist()}')\n",
        "\n",
        "def gunzip(gzfile, fout):\n",
        "    with gzip.open(gzfile, 'rb') as f_in:\n",
        "        with open(fout, 'wb') as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "    print(f'{gzfile} extracted to {fout}')\n",
        "\n",
        "\n",
        "def parse(path):\n",
        "    g = gzip.open(path, 'rb')\n",
        "    for l in g:\n",
        "        yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "    df = {}\n",
        "    i = 0\n",
        "    for d in parse(path):\n",
        "        df[i] = d\n",
        "        i += 1\n",
        "    return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "\n",
        "# map punctuation to space\n",
        "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) \n",
        "\n",
        "def text_preprocessing(df):\n",
        "    \"\"\"\n",
        "    Preprocess the text for better understanding\n",
        "    \n",
        "    \"\"\"\n",
        "    # trim the whitespace at the edges of the string\n",
        "    df['reviewText'] = df['reviewText'].str.strip()\n",
        "\n",
        "    # lowercase the text in the string\n",
        "    df['reviewText'] = df['reviewText'].str.lower()\n",
        "\n",
        "    # replace new line with a .\n",
        "\n",
        "    df['reviewText'] = df['reviewText'].replace('\\n', '.')\n",
        "\n",
        "    # # remove the punctualtion in the string.\n",
        "    # df['reviewText'] = df['reviewText'].str.replace('.', ' [EOS] ')\n",
        "    # df['reviewText'] = df['reviewText'].apply(lambda text: text.translate(translator))\n",
        "    # df['reviewText'] = df['reviewText'].str.replace('[EOS]', ' . ')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "filename = wget(\"https://nlp.stanford.edu/data/glove.6B.zip\")\n",
        "unzip(filename)\n",
        "Video_Games_5 = wget('http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz')\n",
        "df = getDF(Video_Games_5)\n",
        "df = df[['reviewText', 'overall']]\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (862182613 of 862182613) |##########| Elapsed Time: 0:02:40 Time:  0:02:40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloaded to glove.6B.zip\n",
            "extraction done ['glove.6B.50d.txt', 'glove.6B.100d.txt', 'glove.6B.200d.txt', 'glove.6B.300d.txt']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (154050105 of 154050105) |##########| Elapsed Time: 0:00:03 Time:  0:00:03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloaded to Video_Games_5.json.gz\n",
            "(497577, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrmN_k9Fsp-P"
      },
      "source": [
        "import string\n",
        "\n",
        "# map punctuation to space\n",
        "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) \n",
        "\n",
        "def text_preprocessing(df):\n",
        "    \"\"\"\n",
        "    Preprocess the text for better understanding\n",
        "    \n",
        "    \"\"\"\n",
        "    # trim the whitespace at the edges of the string\n",
        "    df['reviewText'] = df['reviewText'].str.strip()\n",
        "\n",
        "    # lowercase the text in the string\n",
        "    df['reviewText'] = df['reviewText'].str.lower()\n",
        "\n",
        "    # remove the punctualtion in the string.\n",
        "    df['reviewText'] = df['reviewText'].apply(lambda text: text.translate(translator))\n",
        "\n",
        "    return df\n",
        "\n",
        "df = df.dropna()\n",
        "df = df.drop_duplicates()\n",
        "df = text_preprocessing(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NErE_cggtZyR",
        "outputId": "01018cb4-1376-4d5a-86eb-a9b884bf320d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this game is a bit hard to get the hang of  bu...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i played it a while but it was alright  the st...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ok game</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>found the game a bit too complicated  not what...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great game  i love it and have played it since...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          reviewText  overall\n",
              "0  this game is a bit hard to get the hang of  bu...      5.0\n",
              "1  i played it a while but it was alright  the st...      4.0\n",
              "2                                           ok game       3.0\n",
              "3  found the game a bit too complicated  not what...      2.0\n",
              "4  great game  i love it and have played it since...      5.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4TTwbSwuuDl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}