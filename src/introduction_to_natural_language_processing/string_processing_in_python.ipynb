{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twjhen423-ci"
   },
   "source": [
    "## The `str` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7tbEADIsKs5",
    "outputId": "04ebf95e-cbc9-44ec-d077-14ba39f73fd5"
   },
   "outputs": [],
   "source": [
    "text = \"quick brown fox jumps over the lazy dog.\"\n",
    "print(type(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fotNJAUn4G-t"
   },
   "source": [
    "## Working with Unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tgZnAzSYsQmV",
    "outputId": "04f91c88-2eae-438a-f642-b5879cda1cb1"
   },
   "outputs": [],
   "source": [
    "text = \"El Ni√±o\".encode(\"utf-8\")\n",
    "print('original text: ', text)\n",
    "print('text after decoding: ', text.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "latP8BSP4M7s"
   },
   "source": [
    "### Size of different strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzbBYcY-sSZO",
    "outputId": "ce1c4f17-2c2a-411b-9102-f59563ba0ad3"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "string = 'hello'\n",
    "print(sys.getsizeof(string))\n",
    "\n",
    "# one byte encoding\n",
    "print(sys.getsizeof(string+'!')-sys.getsizeof(string))\n",
    "\n",
    "# 2-byte encoding\n",
    "string2  = '‡¶Ö'\n",
    "print(sys.getsizeof(string2+'‡¶Ö')-sys.getsizeof(string2))\n",
    "print(sys.getsizeof(string2))\n",
    "\n",
    "# 4-byte encoding\n",
    "string3 = 'üêç'\n",
    "print(sys.getsizeof(string3+'üíª')-sys.getsizeof(string3))\n",
    "print(sys.getsizeof(string3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63_tFyx14T8E"
   },
   "source": [
    "## Common Python string methods\n",
    "\n",
    "### Character lengths and word lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mNCEOA3HsUIh",
    "outputId": "4ca135b5-34e2-4fb6-bd32-163377a0dfc0"
   },
   "outputs": [],
   "source": [
    "string = 'natural language processing for professionals'\n",
    "print('character length of the sentence:', len(string))\n",
    "\n",
    "words = string.split()\n",
    "print('word length of the sentence:', len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdC3i4Fi4bGL"
   },
   "source": [
    "### Character frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzM2TV8ssXGb",
    "outputId": "d300fc5c-e3f8-431e-88d6-36a6b24ea32c"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(Counter('natural language processing for professionals'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_2c54yB4eDW"
   },
   "source": [
    "### Pattern Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLKiMjEtsZYu",
    "outputId": "23603deb-a9ab-42bb-beed-5470e638a579"
   },
   "outputs": [],
   "source": [
    "spam_string = \"click on http://spam.com\"\n",
    "\n",
    "print('http' in spam_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BASnOWYzsa2V",
    "outputId": "837b1e9c-d474-48b2-a753-39ab5ab18fe6"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def url_present(text):\n",
    "    pattern = 'http.*\\.com'\n",
    "    if re.search(pattern, spam_string):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "spam_string = \"click on http://spam.com\"\n",
    "print(url_present(spam_string))\n",
    "\n",
    "spam_string = \"update on ticket\"\n",
    "print(url_present(spam_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtMbPC414kqd"
   },
   "source": [
    "### Strip whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1x4AxA_sfWV",
    "outputId": "cf7ac2e0-879b-4533-ef10-9a4d398b4cae"
   },
   "outputs": [],
   "source": [
    "string_with_whitespace = \"    I am without whitespace. \\n\"\n",
    "string_without_whitespace = \"I am without whitespace.\"\n",
    "print('Equality of the two strings: ',\n",
    "  string_without_whitespace==string_with_whitespace)\n",
    "print('Equality of the strings after performing strip on string_without_whitespace: ',\n",
    "  string_with_whitespace.strip()==string_without_whitespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYCKA_-24oeS"
   },
   "source": [
    "### Splitting Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0800gS5OsijQ",
    "outputId": "5a7303d4-6b8d-4ba9-cffa-5acb6065cf1f"
   },
   "outputs": [],
   "source": [
    "document = \"learning natural language processing\"\n",
    "print(document.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT_W4Au44szv"
   },
   "source": [
    "### Joining list elements in a contiguous string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUwylV7iske_",
    "outputId": "c71f920a-5391-4fd3-ae7c-0093c3c2b3d3"
   },
   "outputs": [],
   "source": [
    "tokens = ['learning', 'natural', 'language', 'processing']\n",
    "print(\" \".join(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5u99IXMC5GcU"
   },
   "source": [
    "### Case of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oxwm3ZYzsl24",
    "outputId": "8d050135-80e2-4fdb-8e11-2b8b16b69ad5"
   },
   "outputs": [],
   "source": [
    "string = \"EDUCATIVE\"\n",
    "print('unique object identification of `string`', id(string))\n",
    "\n",
    "lower_case = string.lower()\n",
    "print('sentence in lower case: ', lower_case)\n",
    "print('unique object identification of `lower_case`', id(lower_case))\n",
    "\n",
    "upper_case = lower_case.upper()\n",
    "print('sentence in upper case: ', upper_case)\n",
    "print('unique object identification of `upper_case`', id(upper_case))\n",
    "\n",
    "print('is a match with the original text: ', upper_case == string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrwnpBe05Nlg"
   },
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qU6F60pasnWC",
    "outputId": "74a7d886-1444-40fa-b40e-f1908d627196"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s1 = pd.Series(\n",
    "    ['string processing using vanila python',\n",
    "     'string processing in pandas']\n",
    ")\n",
    "print(s1)\n",
    "print()\n",
    "print('converting all the strings to uppercase')\n",
    "print(s1.str.upper())\n",
    "print()\n",
    "print('converting all the strings to lowercase')\n",
    "print(s1.str.lower())\n",
    "print()\n",
    "print('split all the sentences to words')\n",
    "print(s1.str.strip().str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9c7q1zeY5RUy"
   },
   "source": [
    "## Amazon reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_si4H-ltMry",
    "outputId": "0d5287d9-9a5e-42d4-a8bd-6949e4408e77"
   },
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import progressbar\n",
    "import zipfile\n",
    "import gzip\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "pbar = None\n",
    "\n",
    "\n",
    "def show_progress(block_num, block_size, total_size):\n",
    "    global pbar\n",
    "    if pbar is None:\n",
    "        pbar = progressbar.ProgressBar(maxval=total_size)\n",
    "        pbar.start()\n",
    "\n",
    "    downloaded = block_num * block_size\n",
    "    if downloaded < total_size:\n",
    "        pbar.update(downloaded)\n",
    "    else:\n",
    "        pbar.finish()\n",
    "        pbar = None\n",
    "\n",
    "def wget(url):\n",
    "    a = urlparse(url)\n",
    "    filename = os.path.basename(a.path)\n",
    "    if not os.path.isfile(filename):\n",
    "        req.urlretrieve(url, filename, show_progress)\n",
    "        print(f'downloaded to {filename}')\n",
    "    else:\n",
    "        print(f'file {filename} has already been downloaded')\n",
    "    return filename\n",
    "\n",
    "def unzip(filename, directory_to_extract_to=os.getcwd()):\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(directory_to_extract_to)\n",
    "        print(f'extraction done {zip_ref.namelist()}')\n",
    "\n",
    "def gunzip(gzfile, fout):\n",
    "    with gzip.open(gzfile, 'rb') as f_in:\n",
    "        with open(fout, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    print(f'{gzfile} extracted to {fout}')\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "    df = {}\n",
    "    i = 0\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "\n",
    "# map punctuation to space\n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) \n",
    "\n",
    "def text_preprocessing(df):\n",
    "    \"\"\"\n",
    "    Preprocess the text for better understanding\n",
    "    \n",
    "    \"\"\"\n",
    "    # trim the whitespace at the edges of the string\n",
    "    df['reviewText'] = df['reviewText'].str.strip()\n",
    "\n",
    "    # lowercase the text in the string\n",
    "    df['reviewText'] = df['reviewText'].str.lower()\n",
    "\n",
    "    # replace new line with a .\n",
    "\n",
    "    df['reviewText'] = df['reviewText'].replace('\\n', '.')\n",
    "\n",
    "    # # remove the punctualtion in the string.\n",
    "    # df['reviewText'] = df['reviewText'].str.replace('.', ' [EOS] ')\n",
    "    # df['reviewText'] = df['reviewText'].apply(lambda text: text.translate(translator))\n",
    "    # df['reviewText'] = df['reviewText'].str.replace('[EOS]', ' . ')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "filename = wget(\"https://nlp.stanford.edu/data/glove.6B.zip\")\n",
    "unzip(filename)\n",
    "Video_Games_5 = wget('http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz')\n",
    "df = getDF(Video_Games_5)\n",
    "df = df[['reviewText', 'overall']]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrmN_k9Fsp-P"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# map punctuation to space\n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) \n",
    "\n",
    "def text_preprocessing(df):\n",
    "    \"\"\"\n",
    "    Preprocess the text for better understanding\n",
    "    \n",
    "    \"\"\"\n",
    "    # trim the whitespace at the edges of the string\n",
    "    df['reviewText'] = df['reviewText'].str.strip()\n",
    "\n",
    "    # lowercase the text in the string\n",
    "    df['reviewText'] = df['reviewText'].str.lower()\n",
    "\n",
    "    # remove the punctualtion in the string.\n",
    "    df['reviewText'] = df['reviewText'].apply(lambda text: text.translate(translator))\n",
    "\n",
    "    return df\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df = text_preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NErE_cggtZyR",
    "outputId": "01018cb4-1376-4d5a-86eb-a9b884bf320d"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4TTwbSwuuDl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "string_processing_in_python",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
