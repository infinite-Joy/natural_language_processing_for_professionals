# -*- coding: utf-8 -*-
"""model_monitoring_and_testing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gKz4Pc8fwF6Skgy3thQga5IClBaaaurA

## load the data
"""

import urllib.request as req
from urllib.parse import urlparse
import os
import progressbar
import zipfile
import gzip
import shutil
import json
import pandas as pd
import re
import string

pbar = None


def show_progress(block_num, block_size, total_size):
    global pbar
    if pbar is None:
        pbar = progressbar.ProgressBar(maxval=total_size)
        pbar.start()

    downloaded = block_num * block_size
    if downloaded < total_size:
        pbar.update(downloaded)
    else:
        pbar.finish()
        pbar = None

def wget(url):
    a = urlparse(url)
    filename = os.path.basename(a.path)
    if not os.path.isfile(filename):
        req.urlretrieve(url, filename, show_progress)
        print(f'downloaded to {filename}')
    else:
        print(f'file {filename} has already been downloaded')
    return filename

Video_Games_5 = wget('http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz')
df = pd.read_json("./Video_Games_5.json.gz", lines=True, compression='gzip')


# some simple preprocessing
df = df[df['reviewText'].notnull()]
df['reviewText'] = df['reviewText'].str.lower()
df['reviewText'] = df['reviewText'].str.replace('[{}]'.format(string.punctuation), '')
df['reviewText'] = df['reviewText'].str.replace('\n', ' ')

df.head()

from datetime import datetime

def year_month(unixReviewTime):
    time = datetime.utcfromtimestamp(unixReviewTime)
    return f'{time.year}{time.month:02d}'

df['year_month'] = df.unixReviewTime.apply(year_month)
df.head(5)

df.year_month.value_counts().sort_values(ascending=False).head()

df[df.year_month=='201501'].overall.value_counts().sort_values()

df[df.year_month=='201502'].overall.value_counts().sort_values()

old_df = df[df.year_month=='201501']
new_df = df[df.year_month=='201502']

"""## drift understanding using visualisation"""

import random

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

vis_df = pd.concat(axis=0, ignore_index=True, objs=[
    pd.DataFrame.from_dict({'value': list(old_df.overall), 'name': '201501'}),
    pd.DataFrame.from_dict({'value': list(new_df.overall), 'name': '201502'})
])
fig, ax = plt.subplots()
sns.histplot(
    data=vis_df, x='value', hue='name', multiple='dodge', alpha=0.5, shrink=.8,
    bins=[1,2,3,4,5], ax=ax
)

"""## difference using kl divergence and earth movers distance

current difference
"""

from scipy.stats import wasserstein_distance, entropy

x = old_df.overall.value_counts().sort_index()
y = new_df.overall.value_counts().sort_index()

print('wasserstein_distance:', wasserstein_distance(x, y))
print('kl divergence:', entropy(x, y))

"""if they are exactly the same"""

print('wasserstein_distance:', wasserstein_distance(x, x))
print('kl divergence:', entropy(x, x))

y

"""if around 500 people suddenly got discgrunted due to some issue"""

y_ = y
print('original y', y_)
y_.loc[1] += 1000
y_.loc[5] -= 1000
print('changed y', y_)

print('wasserstein_distance:', wasserstein_distance(x, y_))
print('kl divergence:', entropy(x, y_))

y_ = y
print('original y', y_)
y_ = [int(.7 * item) for item in y_]
print('changed y', y_)

print('wasserstein_distance:', wasserstein_distance(x, y_))
print('kl divergence:', entropy(x, y_))

print(0.00022072692190882215/0.00012718655172293302, 653.8/83.99999999999999)

"""## discriminative classifier

going ahead with fasttext but you can go ahead with any model of your choice.

fasttext has good out of vocabulary support and there are a lot of spelling mistakes in the data
"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip
# unzip v0.9.2.zip
# cd fastText-0.9.2
# make
# pip install .

!cd fastText-0.9.2 && ./fasttext

old_df['new_data'] = '__label__old'
new_df['new_data'] = '__label__new'

total_df = pd.concat([old_df, new_df])
total_df['ft_data'] = total_df.new_data + ' ' + total_df.reviewText

total_df.head()

"""### train test split"""

from sklearn.model_selection import train_test_split

train_df, test_df = train_test_split(total_df, test_size=0.3, random_state=42)

train_df['ft_data'].to_csv('train.txt', index=False, header=False)
test_df['ft_data'].to_csv('test.txt', index=False, header=False)

!head train.txt

"""### train the model"""

import fasttext
model = fasttext.train_supervised(input="train.txt")

model.test("test.txt")

"""### model evaluation"""

test_df['new_data1'] = test_df['new_data'].apply(lambda x: int(x == '__label__new'))
test_df.head()

import sklearn.metrics as metrics

def ft_prediction_wrapper(texts, model):
    labels = []
    for text in texts:
        labeled, confidences = model.predict(text, k=-1)
        label = dict(zip(labeled, confidences))
        labels.append(label)
    df = pd.DataFrame(labels)
    return df

# calculate the fpr and tpr for all thresholds of the classification
probs = ft_prediction_wrapper(test_df.reviewText.values.tolist(), model)
preds = probs.values[:,1]
y_test = test_df['new_data1'].values
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)

# method I: plt
import matplotlib.pyplot as plt
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

test_df.new_data.value_counts()

